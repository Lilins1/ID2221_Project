import os
import uuid
from dotenv import load_dotenv
import chromadb
from chromadb.utils import embedding_functions
from langchain.text_splitter import RecursiveCharacterTextSplitter
from typing import List, Dict, Optional

# åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆå¦‚æœéœ€è¦é…ç½®åµŒå…¥æ¨¡å‹è·¯å¾„ç­‰ï¼‰
load_dotenv()

class LocalMedicalRAG:
    def __init__(self):
        """åˆå§‹åŒ–æœ¬åœ°RAGç»„ä»¶ï¼ˆæ— éœ€S3ï¼‰"""
        # åˆå§‹åŒ–ChromaDBï¼ˆæœ¬åœ°æŒä¹…åŒ–å­˜å‚¨ï¼‰
        self.chroma_client = chromadb.PersistentClient(path="./local_medical_chroma_db")
        
        # åˆå§‹åŒ–åŒ»å­¦åµŒå…¥æ¨¡å‹
        self.embedding_func = embedding_functions.HuggingFaceEmbeddingFunction(
            model_name="pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb"
        )
        
        # åˆå§‹åŒ–æ–‡æœ¬åˆ‡åˆ†å™¨ï¼ˆé’ˆå¯¹åŒ»å­¦æ–‡æ¡£ä¼˜åŒ–ï¼‰
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=400,
            chunk_overlap=50,
            separators=["\n\n", "\n", ". ", " ", ""]
        )
        
        # è·å–æˆ–åˆ›å»ºChromaé›†åˆ
        self.collection = self.chroma_client.get_or_create_collection(
            name="local_medical_docs",
            embedding_function=self.embedding_func,
            metadata={"description": "æœ¬åœ°åŒ»å­¦æ–‡æ¡£RAGæµ‹è¯•"}
        )

    def load_local_document(self, file_path: str) -> Optional[Dict]:
        """ä»æœ¬åœ°åŠ è½½æ–‡æœ¬æ–‡ä»¶"""
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(file_path):
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return None
            
            # è¯»å–æ–‡ä»¶å†…å®¹
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            # æå–å…ƒæ•°æ®
            metadata = {
                "local_path": file_path,
                "file_name": os.path.basename(file_path),
                "file_size": len(content),
                "last_modified": os.path.getmtime(file_path)
            }
            
            return {
                "content": content,
                "metadata": metadata
            }
        except Exception as e:
            print(f"âŒ åŠ è½½æœ¬åœ°æ–‡ä»¶å¤±è´¥: {str(e)}")
            return None

    def split_document(self, content: str) -> List[str]:
        """åˆ‡åˆ†æ–‡æ¡£ä¸ºç‰‡æ®µ"""
        return self.text_splitter.split_text(content)

    def process_and_store_local(self, file_path: str, category: str) -> bool:
        """å¤„ç†æœ¬åœ°æ–‡ä»¶å¹¶å­˜å‚¨åˆ°ChromaDB"""
        # 1. åŠ è½½æœ¬åœ°æ–‡æ¡£
        doc_data = self.load_local_document(file_path)
        if not doc_data:
            return False
        
        # 2. åˆ‡åˆ†æ–‡æ¡£
        chunks = self.split_document(doc_data["content"])
        if not chunks:
            print("âŒ æ–‡æ¡£åˆ‡åˆ†åæ— å†…å®¹")
            return False
        
        print(f"âœ… æ–‡æ¡£åˆ‡åˆ†å®Œæˆ: {len(chunks)}ä¸ªç‰‡æ®µ")
        
        # 3. å‡†å¤‡å­˜å‚¨æ•°æ®
        ids = [f"{uuid.uuid4()}" for _ in chunks]
        metadatas = [{
            **doc_data["metadata"],
            "chunk_id": i,
            "category": category
        } for i in range(len(chunks))]
        
        # 4. å­˜å‚¨åˆ°ChromaDB
        try:
            self.collection.add(
                ids=ids,
                documents=chunks,
                metadatas=metadatas
            )
            print(f"âœ… æˆåŠŸå­˜å‚¨åˆ°ChromaDB: {os.path.basename(file_path)}")
            return True
        except Exception as e:
            print(f"âŒ å­˜å‚¨å¤±è´¥: {str(e)}")
            return False

    def batch_process_local_dir(self, dir_path: str, category: str) -> Dict:
        """æ‰¹é‡å¤„ç†æœ¬åœ°ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡æœ¬æ–‡ä»¶"""
        stats = {"total": 0, "success": 0, "failed": 0}
        
        if not os.path.isdir(dir_path):
            print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {dir_path}")
            return stats
        
        # éå†ç›®å½•ä¸‹çš„æ‰€æœ‰txtæ–‡ä»¶
        for root, _, files in os.walk(dir_path):
            for file in files:
                if file.endswith(".txt"):  # åªå¤„ç†txtæ–‡ä»¶
                    file_path = os.path.join(root, file)
                    stats["total"] += 1
                    print(f"\nå¤„ç†æ–‡ä»¶ {stats['total']}: {file}")
                    
                    if self.process_and_store_local(file_path, category):
                        stats["success"] += 1
                    else:
                        stats["failed"] += 1
        
        print(f"\nğŸ“Š æ‰¹é‡å¤„ç†å®Œæˆ: å…±{stats['total']}ä¸ª, æˆåŠŸ{stats['success']}ä¸ª, å¤±è´¥{stats['failed']}ä¸ª")
        return stats

    def retrieve_local(self, query: str, n_results: int = 3, category: Optional[str] = None) -> List[Dict]:
        """æ£€ç´¢ç›¸å…³æ–‡æ¡£ç‰‡æ®µ"""
        where_clause = {"category": category} if category else None
        
        results = self.collection.query(
            query_texts=[query],
            n_results=n_results,
            where=where_clause
        )
        
        # æ•´ç†ç»“æœ
        return [{
            "id": results['ids'][0][i],
            "content": results['documents'][0][i],
            "metadata": results['metadatas'][0][i],
            "similarity_score": 1 - results['distances'][0][i]
        } for i in range(len(results['ids'][0]))]

if __name__ == "__main__":
    # åˆå§‹åŒ–æœ¬åœ°RAG
    local_rag = LocalMedicalRAG()
    
    # é…ç½®ä½ çš„æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼ˆè¯·ä¿®æ”¹ä¸ºå®é™…è·¯å¾„ï¼‰
    # å•ä¸ªæ–‡ä»¶æµ‹è¯•
    SINGLE_FILE_PATH = r"C:\Users\Ruizhe\Desktop\Study\ID2221\Project\S3\LocalData\PMC000xxxxxxtxt\PMC466938.txt"  # ä½ çš„æœ¬åœ°æ–‡ä»¶è·¯å¾„
    # ç›®å½•æ‰¹é‡æµ‹è¯•ï¼ˆå¦‚æœæœ‰å¤šä¸ªæ–‡ä»¶ï¼‰
    DIR_PATH = r"C:\Users\Ruizhe\Desktop\Study\ID2221\Project\S3\LocalData\PMC000xxxxxxtxt"  # åŒ…å«å¤šä¸ªtxtæ–‡ä»¶çš„ç›®å½•
    DOC_CATEGORY = "medical_research"  # æ–‡æ¡£åˆ†ç±»
    
    # 1. å¤„ç†å•ä¸ªæ–‡ä»¶ï¼ˆäºŒé€‰ä¸€ï¼Œæ ¹æ®éœ€è¦æ³¨é‡Šï¼‰
    print("===== å¤„ç†å•ä¸ªæ–‡ä»¶ =====")
    local_rag.process_and_store_local(SINGLE_FILE_PATH, DOC_CATEGORY)
    
    # # 2. æ‰¹é‡å¤„ç†ç›®å½•ï¼ˆå¦‚æœæœ‰å¤šä¸ªæ–‡ä»¶ï¼Œå–æ¶ˆæ³¨é‡Šï¼‰
    # print("\n===== æ‰¹é‡å¤„ç†ç›®å½• =====")
    # local_rag.batch_process_local_dir(DIR_PATH, DOC_CATEGORY)
    
    # 3. æµ‹è¯•æ£€ç´¢åŠŸèƒ½
    print("\n===== æµ‹è¯•æ£€ç´¢ =====")
    test_queries = [
        "è‚ºç™Œçš„è¯Šæ–­æ–¹æ³•",
        "é¶å‘æ²»ç–—çš„å‰¯ä½œç”¨",
        "ä¸´åºŠè¯•éªŒçš„ç»“æœåˆ†æ"
    ]
    
    for query in test_queries:
        print(f"\næŸ¥è¯¢: {query}")
        print("-------------------")
        results = local_rag.retrieve_local(
            query=query,
            n_results=2,
            category=DOC_CATEGORY
        )
        
        for i, res in enumerate(results, 1):
            print(f"ç»“æœ {i} (ç›¸ä¼¼åº¦: {res['similarity_score']:.4f})")
            print(f"æ¥æº: {res['metadata']['local_path']}")
            print(f"ç‰‡æ®µ: {res['content'][:200]}...")
